# -*- coding: utf-8 -*-
"""VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWNDLzhMsEEHB61_fhEWUevqtnkOhFHV
"""

#import library
from keras.layers import Dense,Flatten,Conv2D,Activation,Dropout,BatchNormalization
import keras
import tensorflow as tf
from keras.models import Sequential, Model
from keras.models import load_model
from tensorflow.keras.optimizers import SGD
from keras.layers import MaxPool2D
from tensorflow.keras import regularizers
from keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
from keras.utils.vis_utils import plot_model

#kết nối đến google drive
from google.colab import drive
drive.mount('/content/drive')

#xác định batch_size và kích thước ảnh
batch_size = 64
img_height = 224
img_width = 224
#lấy dữ liệu cho tập train từ google với 80% cho tập train và 20% cho tập validate
train_ds = tf.keras.utils.image_dataset_from_directory(
  '/content/drive/MyDrive/fruitDataset/dataset/train',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
# lấy dữ liệu cho tập đánh giá
val_ds = tf.keras.utils.image_dataset_from_directory(
  '/content/drive/MyDrive/fruitDataset/dataset/validation',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
test_ds = tf.keras.utils.image_dataset_from_directory(
  '/content/drive/MyDrive/fruitDataset/dataset/test',
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
class_names = train_ds.class_names   # Tên  các lớp của tập dữ liệu
num_classes=len(class_names) #Số lượng lớp của tập dữ liệu

#hiển thị 9 ảnh bất kì với nhãn tương ứng
plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

# hàm tạo model
def VGG16():
    model = Sequential()
    # thêm lớp tích chập với dữ liệu đầu vào là ảnh rgb 224x224, số lượng filters=64, kích thước kernel=3x3, padding với p=1, hàm kích hoạt là hàm relu.
    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding="same", activation="relu"))
    model.add(Conv2D(filters=64,kernel_size=(3,3),padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2))) # lớp maxpooling với pool_size=2x2, stride=2x2 làm giảm kích thước dữ liệu đi 1 nửa
    model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu"))
    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))
    model.add(Flatten(name='flatten')) #chuyển dữ liệu về dạng nhiều chiều (dạng như mảng)
    model.add(Dense(4096, activation='relu', name='fc1')) # lớp full connected với 4096 node.
    model.add(BatchNormalization())
    model.add(Dropout(0.5)) # lớp dropout loại bỏ ngẫu nhiên 50% thuộc tính để tránh overfitting.
    model.add(Dense(4096, activation='relu', name='fc2'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax', name='output')) #lớp fullconnected với số node là số lượng lớp của bộ dữ liệu, hàm kích hoạt là softmax
    return model

model=VGG16() #Khởi tạo model
model.summary() 
plot_model(model, to_file='/content/drive/MyDrive/Colab Notebooks/model_plot.png', show_shapes=True, show_layer_names=True)

Vgg16 = Model(inputs=model.input, outputs=model.get_layer('vgg16').output) #Vgg16 = từ layers input -> layers vgg16 của model

Vgg16.load_weights("/content/drive/MyDrive/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5") # sử dụng model đã được train với bộ dữ liệu ImageNet để nạp các hệ số tương ứng cho Vgg16

for layer in Vgg16.layers:
    layer.trainable = False

opt = SGD(learning_rate=1e-4, momentum=0.9) #  hàm tối ưu là stochastic gradient descent
model.compile(loss="sparse_categorical_crossentropy", optimizer='adam',metrics=["accuracy"])

epochs=20
history= model.fit(train_ds,validation_data=val_ds,epochs=epochs) # train model với 20 epochs

# dự đoán kết quả của 1 ảnh được đọc vào từ drive
img=image.load_img('/content/drive/MyDrive/Garbage Classification/train/Metal/Metal_113.jpg',target_size=(img_height,img_width))
imgplot = plt.imshow(img)
img_tensor = image.img_to_array(img)                   
img_tensor = np.expand_dims(img_tensor, axis=0)       
score=model.predict(img_tensor)
plt.title(class_names[np.argmax(score)]+".  confident:"+str(int(100*np.max(score)))+'%')
plt.show()

# Kiểm tra mô hình
from keras.preprocessing import image
plt.figure(figsize=(20, 20))
for images, labels in test_ds.take(1): 
  for i in range(9): # lấy ngẫu nhiên 9 ảnh từ tập test
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8")) 
    img_tensor = image.img_to_array(images[i]) # chuyển ảnh sang dạng  3 ma trận 2 chiều                  
    img_tensor = np.expand_dims(img_tensor, axis=0) # chuyển thành 1 ma trận 3 chiều     
    x=model.predict(img_tensor) #mô hình dự đoán kết quả
    plt.title("Actual:"+class_names[labels[i]]+" Predict:"+class_names[np.argmax(x)]+" Prob:"+str(int(100*np.max(x)))+'%') # so sánh kết quả  dự đoán và nhãn của ảnh
    plt.axis("off")

model.evaluate(test_ds)

# vẽ đồ thị thể hiện kết quả của model
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

#lưu model
model.save('/content/drive/MyDrive/Project1Dataset/batchProject1VGG16.h5')